Machine Learning Project: Brain Fingerprint from the brain activity
==========
In partnership with the Medical Image Processing Lab (MIP:Lab)

Supervisors: Hamid Behjat and Ekansh Sareen


Overview
========
It has previously been shown that it is possible to identify individuals using brain activity signals such as functional Magnetic Resonance Imaging (fMRI) or magnetoencephalography (MEG), a process known as brain fingerprinting. Until now, this has always been done by computing statistical brain region dependencies to build functional connectivity (FC) matrices. Here we explore a new approach of brain fingerprinting using MEG data that differs from previous methods in two ways. First, we use the brain signals to learn brain graphs instead of computing FC matrices. Secondly, we explore the use of machine learning classifiers to identify individuals instead of computing inter-subjects correlations. <br/>
<br/>


Directory layout
================

    Directory                           # Main directory
    
    ├── data_sets
            ├────── Test_set
            └─────── Train_set    
    ├── plots
            ├────── SVM_l2_all_epochs_accuracies.png
            └─────── SVM_log_all_epochs__accuracies.png 
    ├── utils
            ├────── HCP_info
                          └────── MEG84_subjects_ID.mat
            └────── gspbox                                  
    ├── Data_Visualisation.ipynb
    ├── README.md
    ├── create_datasets.py
    ├── create_accuracy_plots.py
    ├── helpers.py
    ├── plots.py
    ├── models.py
    ├── run_Random_Forest.py
    ├── run_Random_Forest_all_epochs.py
    ├── run_SVM.py
    ├── run_SVM_all_epochs.py
    ├── run_SVM_without_var.py
    ├── run_correlations.py
    ├── run_correlation_all_epochs.py
    ├── run_sparsity.py
    ├── scr_learn_graph_LEA_allsubjs.m    
    └── Report.pdf
     



Description of contents
==============

Directories:
---------
Directory name                  | description
--------------------------------|------------------------------------------
utils					        | Contains the gspbox package and HCP labels needed to run the scr_learn_graph_LEA_allsubjs.m script
data_sets           		    | Contains all the data sets built when running create_datasets.py. Since the MEG data used to generate our train and test set is                                     too heavy to be put in our repository, we provide here a few of the train and test sets we have built.
plots           		  	    | All the figure generated by our scripts will be saved in this directory, i.e. the accuracy plots and the confusion matrices
sample_data         		    | Since the raw data use to build our data set is to heavy, this folder is not present in our repository. However, this is where the                                   MEG data used to learn the brain graphs should be included. Once the learned brain graphs are generated, they should also be                                         included in this directory in order to be able to run the file create_datasets.py.  


Non Python files:
-----------

filename                        | description
--------------------------------|------------------------------------------
README.md                       | Text file (markdown format) describing all the files of the project and its architecure
Data_Visualisation.ipynb        | Jupyter Notebook containing the visualization of the data and its exploration. The reasoning of pre processing can be found inside
scr_learn_graph_LEA_allsubjs.m  | Mathlab file returning the adjacency matrix in function of parameters, see report for a complete explanation. The folder “utils”                                     gives it tools needed to compile.  
Report.pdf                      | Pdf file explaining our project in detail. Every information about the models chosen and the results can be found inside 





Python files:
---------

filename                        | description
--------------------------------|------------------------------------------
create_datasets.py              |
create_accuracy_plots.py	    | This file creates different plots of the best accuracy of our models with regards to each of the learned graph sparsity                                             parameters. To run it without modifying the paths the .csv results files need to be stored in the folders at the following path                                     starting from this repository: SVM results: ../SVM, RandomForest results: ../results/RandomForest, correlation results:                                             ../results/correlations. 
helpers.py                      | Set of useful functions used throughout the project
plots.py                        |
models.py                       |
run_Random_Forest.py            |Compute the accuracy of the Random Forest model per epochs using a chosen regularization and frequency bands. To determine the best                                  parameters of the Random Forest model a grid search can be performed. An accuracy table is stored in a csv file inside a Random                                      Forest folder: r'../results/RandomForest'
run_Random_Forest_all_epochs.py |Compute the accuracy of the Random Forest model using an average of all epochs and a chosen regularization and frequency bands. To                                  determine the best parameters of the Random Forest model a grid search can be performed. An accuracy table is stored in a csv file                                  inside a Random Forest folder: r'../results/RandomForest'
run_SVM.py                      |Compute the accuracy of the SVM model per epochs using a chosen regularization and frequency bands. To determine the best                                            parameters of the SVM model a grid search can be performed. An accuracy table is stored in a csv file inside a SVM folder:                                          r“../SVM”. 
run_SVM_all_epochs.py           |Compute the accuracy of the SVM model using an average of all epochs, a chosen regularization and frequency bands. To determine the                                  best parameters of the SVM model a grid search can be performed. An accuracy table is stored in a csv file inside a SVM folder:                                      r“../SVM”.
run_SVM_without_var.py          |Compute the accuracy of the SVM model per epochs using a chosen regularization, frequency bands and the best SVM parameters. To                                      determine the best parameters of the SVM model features were removed according to their variance. An accuracy table is stored in a                                  csv file inside a SVM folder: r“../SVM”.
run_correlations.py             |
run_correlation_all_epochs.py   |
run_sparsity.py                 |Use to assess the sparsity of our data per epoch or on an average of them. The sparsity depending on the sparsity parameters,                                        regularisation and frequency band. The results are stored in csv files inside the folders r'../results/sparsity_csv/all_epochs/'                                    and r'../results/sparsity_csv/per_epoch/' according to the choices. The sparsity is plotted in the folder r'plots/’

Authors
=======
Emilie MARCOU, Lucille NIEDERHAUSER & Anabel SALAZAR DORADO
