Machine Learning Project: Brain Fingerprint from the brain activity
==========
In partnership with the Medical Image Processing Lab (MIP:Lab)

Supervisors: Hamid Behjat and Ekansh Sareen


Overview
========
It has previously been shown that it is possible to identify individuals using brain activity signals such as functional Magnetic Resonance Imaging (fMRI) or magnetoencephalography (MEG), a process known as brain fingerprinting. Until now, this has always been done by computing statistical brain region dependencies to build functional connectivity (FC) matrices. Here we explore a new approach of brain fingerprinting using MEG data that differs from previous methods in two ways. First, we use the brain signals to learn brain graphs instead of computing FC matrices. Secondly, we explore the use of machine learning classifiers to identify individuals instead of computing inter-subjects correlations. <br/>
<br/>


Directory layout
================

    Directory                           # Main directory
    
    ├── data_sets
            ├────── Test_set
                          └────── test_wl2_alpha_0.1.txt
            └─────── Train_set 
                          └────── test_wl2_alpha_0.1.txt
    ├── plots
            ├────── SVM_l2_all_epochs_accuracies.png
            └─────── SVM_log_all_epochs__accuracies.png 
    ├── utils
            ├────── HCP_info
                          └────── MEG84_subjects_ID.mat
            └────── gspbox
    ├── sample_data
    ├── Data_Visualisation.ipynb
    ├── README.md
    ├── create_datasets.py
    ├── create_accuracy_plots.py
    ├── helpers.py
    ├── plots.py
    ├── models.py
    ├── run_Random_Forest.py
    ├── run_Random_Forest_all_epochs.py
    ├── run_SVM.py
    ├── run_SVM_all_epochs.py
    ├── run_SVM_without_var.py
    ├── run_correlations.py
    ├── run_correlation_all_epochs.py
    ├── run_sparsity.py
    ├── scr_learn_graph_LEA_allsubjs.m    
    └── ML_Project2_BrainFingerPrinting.pdf

     



Description of contents
==============

Directories:
---------
Directory name                  | description
--------------------------------|------------------------------------------
utils					        | Contains the gspbox package and HCP labels needed to run the scr_learn_graph_LEA_allsubjs.m script
data_sets           		    | Contains all the data sets built when running create_datasets.py and used to train and test our models. Since the MEG data used to generate our train and test set is                                     too heavy to be put in our repository, we provide here a few of the train and test sets we have built.
plots           		  	    | All the figures generated by our scripts will be saved in this directory, i.e. the accuracy plots and the confusion matrices
sample_data         		    | Since the raw data used to build our data set is to heavy, this folder is not present in our repository. However, this is where the                               MEG data used to learn the brain graphs should be included. Once the learned brain graphs are generated, they should also be                                         included in this directory in order to be able to run the file create_datasets.py.  


Non Python files:
-----------

filename                            | description
------------------------------------|------------------------------------------
README.md                           | Text file (markdown format) describing all the files of the project and its architecture
Data_Visualisation.ipynb            | Jupyter Notebook containing the visualization of the data and its exploration. The reasoning of pre processing can be found inside
scr_learn_graph_LEA_allsubjs.m      | Mathlab file returning the adjacency matrix in function of parameters, see ML_Project2_BrainFingerPrinting.pdf for a complete                                       explanation. The folder “utils” contains the tools needed to compile.  
ML_Project2_BrainFingerPrinting.pdf | Pdf file explaining our project in detail. Every information about the models chosen and the results can be found inside 





Python files:
---------

filename                        | description
--------------------------------|------------------------------------------
create_datasets.py              |Create all the data sets from the matrix returned by the mathlab learn graph script “scr_learn_graph_LEA_allsubjs.m” and stored inside the folder sample_data. There is the possibility to create the dataset for all epochs combined or per epoch. These txt files are stored inside the folder: data_set
create_accuracy_plots.py	    | This file creates different plots of the best accuracy of our models with regards to each of the learned graph sparsity parameters. To run it without modifying the paths the .csv results files need to be stored in the folders at the following path starting from this repository: SVM results: ../SVM, RandomForest results: ../results/RandomForest, correlation results:                                             ../results/correlations 
helpers.py                      | Set of useful functions used throughout the project
plots.py                        |A file containing all the functions needed to plot the results we wanted to show. For example, the code to plot the confusion                                         matrices or to plot accuracies of different models can be found here. The plots are saved in the folder plots/ 
models.py                       | Contains all the code related to our SVM and RandomForest models, i.e. the functions used to make predictions, as well as the grid                                    searches and cross validations
run_Random_Forest.py            |Compute the accuracy of the Random Forest model per epochs using a chosen regularization and frequency bands. To determine the best parameters of the Random Forest model a grid search can be performed. An accuracy table is stored in a csv file inside a Random                                      Forest folder: ../results/RandomForest
run_Random_Forest_all_epochs.py |Compute the accuracy of the Random Forest model using a combination of all epochs and a chosen regularization and frequency bands.                                  To determine the best parameters of the Random Forest model a grid search can be performed. An accuracy table is stored in a csv                                    file inside a Random Forest folder: ../results/RandomForest
run_SVM.py                      |Compute the accuracy of the SVM model per epochs using a chosen regularization and frequency bands. To determine the best parameters of the SVM model a grid search can be performed. An accuracy table is stored in a csv file inside a SVM folder:                                          ../SVM
run_SVM_all_epochs.py           |Compute the accuracy of the SVM model using a combination of all epochs, a chosen regularization and frequency bands. To determine the                              best parameters of the SVM model a grid search can be performed. An accuracy table is stored in a csv file inside a SVM folder:                                      ../SVM
run_SVM_without_var.py          |Compute the accuracy of the SVM model per epochs using a chosen regularization, frequency bands and the best SVM parameters. To                                      determine the best parameters of the SVM model features were removed according to their variance. An accuracy table is stored in a                                  csv file inside a SVM folder: ../SVM
run_correlations.py             | Computes the accuracy of predictions by computing the inter-subjects correlations between the train and test sets build using                                       single epochs separately. The train and test sets used are all from the same band and the same regularization that is specified at                                   the begining of the file but all for different sparsity parameters. The results are saved in a .csv file containing all the                                         correlation accuracies for each sparsity parameters at the path ../results/correlations/, starting from this directory
run_correlation_all_epochs.py   | Computes the accuracy of predictions by computing the inter-subjects correlations between the train and test sets build using all                                   epochs combined. The train and test sets used are all from the same regularization that is specified at the begining of the file                                     but all for all different sparsity parameters and all 5 frequency bands. The results are saved in one .csv file per band                                             containing all the correlation accuracies for each sparsity parameters at the path ../results/correlations/, starting from this                                     directory
run_sparsity.py                 | Used to assess the sparsity of our the adjacency matrices built using single epochs or all epochs combined. The sparsity depends on the sparsity parameters,                                     the regularisation and the frequency bands. The results are stored in .csv files inside the folders ../results/sparsity_csv/all_epochs/                                        and ../results/sparsity_csv/per_epoch/ according to the choices. The sparsity plots are saved in the folder plots/

Authors
=======
Emilie MARCOU, Lucille NIEDERHAUSER & Anabel SALAZAR DORADO
